{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Film Recommendation Engine for Classic & International Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from ast import literal_eval\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\AppData\\Local\\Temp\\ipykernel_12488\\3006201849.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  films = pd.read_csv('archive\\\\movies_metadata.csv')\n"
     ]
    }
   ],
   "source": [
    "## Reading CSV Files\n",
    "ratings = pd.read_csv('archive\\\\ratings.csv').loc[0:5000001] ## limited to first 5 million rows\n",
    "films = pd.read_csv('archive\\\\movies_metadata.csv')\n",
    "links = pd.read_csv('archive\\\\links.csv')\n",
    "keywords = pd.read_csv('archive\\\\keywords.csv')\n",
    "films_copy = films.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop null values\n",
    "films.dropna(subset = ['vote_count', 'release_date'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "films = films.drop_duplicates(subset=['id'])\n",
    "keywords = keywords.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert numerical values to integer/float\n",
    "films['budget'] = films['budget'].astype(int)\n",
    "films['id'] = films['id'].astype(int)\n",
    "films['popularity'] = films['popularity'].astype(float)\n",
    "films['revenue'] = films['revenue'].astype(int)\n",
    "films['vote_average'] = films['vote_average'].astype(float)\n",
    "films['vote_count'] = films['vote_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## drop null values and convert to integer\n",
    "films.dropna(subset=['runtime'], inplace = True)\n",
    "films['runtime'] = films['runtime'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## extracting year from release date and converting to integer\n",
    "films['year'] = films['release_date'].str[0:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Remove adult films\n",
    "films = films[films['adult']=='False']\n",
    "## Remove films that have not been released\n",
    "films = films[films['status']=='Released']\n",
    "## Remove Direct-to-Video films\n",
    "films = films[films['video']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Drop nulls from original language column\n",
    "films.dropna(subset='original_language', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films['tmdbId'] = films['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## I will use the Vote Count and Vote Average Columns to calculate a weighted rating.\n",
    "## I can do this using the formula used by IMDB.\n",
    "\n",
    "C = ratings['rating'].mean()\n",
    "m = 20\n",
    "\n",
    "def adjust_rating(vote_mean, vote_count):\n",
    "    \"\"\"A formula to calculate the weighted rating of a film.\n",
    "    Input: Mean rating and total number of votes\n",
    "    Output: Weighted rating using IMDB's formula\n",
    "    \"\"\"\n",
    "    if vote_count > 0:\n",
    "        new_rating = (vote_mean*vote_count/(vote_count+m))+(C*m/(vote_count+m))\n",
    "    else:\n",
    "        ### If there are no ratings, give output as zero\n",
    "        new_rating = 0\n",
    "    return new_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films['adj_rating'] = films.apply(lambda x: adjust_rating(x['vote_average'],x['vote_count']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films = films[['tmdbId','title','year','genres','original_language','original_title','overview','popularity','poster_path','production_companies','production_countries','runtime','spoken_languages','tagline','vote_average','vote_count','adj_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Drop films that do not have an overview\n",
    "films.dropna(subset='overview', inplace=True)\n",
    "## For tagline, replace null values with an empty string\n",
    "films['tagline'] = films['tagline'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films = films[(films['runtime']<240) & (films['runtime']>60)]\n",
    "films = films[films['vote_count']>25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Converting Genre column into a list\n",
    "films['genres'] = films['genres'].apply(literal_eval).apply(lambda x: [genre['name'] for genre in x])\n",
    "\n",
    "### Removing TV Movies and Documentaries from dataframe\n",
    "films = films[films['genres'].apply(lambda x: ('TV Movie' not in x) and ('Documentary' not in x))]\n",
    "\n",
    "## Removing 'Foreign' from genres column\n",
    "films['genres'] = films['genres'].apply(lambda x: [i for i in x if i != 'Foreign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Converting Production Companies, Production Countries and Spoken Languages to lists\n",
    "\n",
    "films['production_companies'] = films['production_companies'].apply(literal_eval).apply(lambda x: [co['name'] for co in x])\n",
    "films['production_countries'] = films['production_countries'].apply(literal_eval).apply(lambda x: [country['name'] for country in x])\n",
    "films['spoken_languages'] = films['spoken_languages'].apply(literal_eval).apply(lambda x: [lang['name'] for lang in x])\n",
    "\n",
    "films['production_countries'] = films['production_countries'].apply(lambda countries: [x.replace('United States of America','USA').replace('United Kingdom','UK') for x in countries])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cleaning Ratings Dataframe\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Adding tmdbId to ratings dataframe so I can join with the films dataframe\n",
    "ratings = ratings.join(links[['movieId','tmdbId']].set_index('movieId'), on='movieId')\n",
    "\n",
    "## Adding Title and Year to the ratings dataframe\n",
    "ratings = ratings.join(films[['tmdbId','title','year','production_countries']].set_index('tmdbId'), on='tmdbId')\n",
    "\n",
    "## Removing ratings for films that are no longer in the films dataframe\n",
    "ratings.dropna(subset='title', inplace=True)\n",
    "ratings['year'] = ratings['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Adding keywords to films dataframe\n",
    "films = films.join(keywords.set_index('id'), on='tmdbId')\n",
    "\n",
    "## Converting keywords to lists\n",
    "films['keywords'] = films['keywords'].apply(literal_eval)\n",
    "films['keywords'] = films['keywords'].apply(lambda x: [key['name'] for key in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_international(countries, languages):\n",
    "    \"\"\"A function to provide a label for international films\n",
    "    Input: The list of productions countries and spoken languages for a film\n",
    "    Output: 1 for international films, 0 for English films\n",
    "\n",
    "    The function allows for an English-speaking country to appear in the production companies if the spoken languages does not include English.\n",
    "    A film that includes spoken English will still count as international if the production companies do not include any English-speaking countries and English is not the only spoken language.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check for English-speaking countries in the production countries\n",
    "    c_intersect = [country for country in countries if country in ['USA','UK','Australia','New Zealand']]\n",
    "    # Check if the film contains spoken English, or no spoken language\n",
    "    l_intersect = [lang for lang in languages if lang in ['English','No Language']]\n",
    "\n",
    "    if languages == ['English']:\n",
    "        label = 0 ## Films with English as the only spoken language\n",
    "    elif len(c_intersect) > 0 and len(l_intersect) > 0:\n",
    "        label = 0 ## Films from an English-speaking country, with spoken English\n",
    "    elif languages==[] or countries==[]:\n",
    "        label = 0 ## Do not label any rows where country/language data is potentially incomplete\n",
    "    else:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Applying labelling function to films dataframe\n",
    "films['international'] = films.apply(lambda x: label_international(x['production_countries'],x['spoken_languages']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films['title_lower'] = films['title'].str.lower().str.replace('[{}]'.format(string.punctuation),'',regex=True).apply(unidecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_films = films.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preparing Summary\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "stpwrd = nltk.corpus.stopwords.words('english')\n",
    "stpwrd.extend(string.punctuation)\n",
    "\n",
    "def prep_summary(summary):\n",
    "    \"\"\"Function to prepare the Summary\n",
    "    Input: single string of text\n",
    "    Output: string of text in lower case, stop words removed, and stemmed\n",
    "    \"\"\"\n",
    "    summary = summary.lower()\n",
    "    summary = word_tokenize(summary)\n",
    "    summary = [word for word in summary if word not in stpwrd]\n",
    "    summary = [p_stemmer.stem(word) for word in summary]\n",
    "    summary = [word for word in summary if word not in stpwrd]\n",
    "    summary = [word for word in summary if word not in ['film','movie']]\n",
    "    summary = [word for word in summary if len(word)>2]\n",
    "    return ' '.join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creating summary where keywords are included twice\n",
    "\n",
    "def concatenate(x):\n",
    "    \"\"\"a function to combine text-based features into a single string, with keywords included twice\n",
    "    Input: separate string for Overview & Tagline, and a list of Keywords\n",
    "    Output: Overview, Tagline and all Keywords (duplicated) in one string\n",
    "    \"\"\"\n",
    "    return x['overview'] + ' ' + x['tagline'] + ' ' + ' '.join(x['keywords']) + ' ' + ' '.join(x['keywords'])\n",
    "\n",
    "df_films['summary'] = df_films.apply(concatenate, axis=1)\n",
    "df_films['summary'] = df_films['summary'].apply(prep_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Calculating Similarity Scores\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Replace 'Science Fiction' with 'Sci-Fi' so it does not affect similarity scores\n",
    "df_films['genres'] = df_films['genres'].apply(lambda x: ' '.join(x)).str.replace('Science Fiction','Sci-Fi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Sort dataframe by year and reindex\n",
    "## This will make it easier to return only older films in the function\n",
    "df_films = df_films.sort_values('year')\n",
    "df_films = df_films.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Converting production countries into a single string for better display\n",
    "df_films['country'] = df_films['production_countries'].apply(lambda x: ', '.join(x))\n",
    "ratings['country'] = ratings['production_countries'].apply(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creating a separate dataframe for international films be reordering and reindexing\n",
    "df_international = df_films.sort_values('international', ascending=False).copy()\n",
    "df_international = df_international.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cosine Similarities for Classic films\n",
    "\n",
    "n = len(df_films[df_films['year']<1967]) # number of rows to be considered\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "summary_matrix = tf.fit_transform(df_films['summary'])\n",
    "summary_sim = linear_kernel(summary_matrix, summary_matrix[0:n])\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', min_df=0, stop_words=None)\n",
    "genre_matrix = tf.fit_transform(df_films['genres'])\n",
    "genre_sim = linear_kernel(genre_matrix, genre_matrix[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cosine Similarities for International films\n",
    "\n",
    "n = len(df_films[df_films['international']==1])\n",
    "\n",
    "### Summary\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "inter_summary_matrix = tf.fit_transform(df_international['summary'])\n",
    "inter_summary_sim = linear_kernel(inter_summary_matrix, inter_summary_matrix[0:n])\n",
    "\n",
    "### Genres\n",
    "tf = TfidfVectorizer(analyzer='word', min_df=0, stop_words=None)\n",
    "inter_genre_matrix = tf.fit_transform(df_international['genres'])\n",
    "inter_genre_sim = linear_kernel(inter_genre_matrix, inter_genre_matrix[0:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Final Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recommend(film, international=False):\n",
    "    \"\"\"retrieves cosine score for summary (2*keywords) & genres\n",
    "    final score by calculating product\n",
    "    returns 10 most similar, then sorts by ratings\"\"\"\n",
    "\n",
    "    if international:\n",
    "        df = df_international\n",
    "        sum_sims = inter_summary_sim\n",
    "        gen_sims = inter_genre_sim\n",
    "    else:\n",
    "        df = df_films\n",
    "        sum_sims = summary_sim\n",
    "        gen_sims = genre_sim\n",
    "\n",
    "    film = unidecode(re.sub(r'[{}]'.format(string.punctuation),'',film.lower()))\n",
    "\n",
    "    ## retrieve film id\n",
    "    if len(df[df['title_lower']==film].index) == 0:\n",
    "        return 'This film could not be found.'\n",
    "    elif len(df[df['title_lower']==film].index) > 1:\n",
    "        year = int(input(\"What year was this film released?\"))\n",
    "        input_id = df[df['title_lower']==film]['year'].apply(lambda x: abs(x-year)).idxmin()\n",
    "    else:\n",
    "        input_id = df[df['title_lower']==film].index[0]\n",
    "    print('Giving recommendations for ' + str(df['title'].iloc[input_id]) + ' (' + str(df['year'].iloc[input_id]) + ')')\n",
    "\n",
    "    ## calculate metric scores\n",
    "    summary_scores = sum_sims[input_id]\n",
    "    genre_scores = gen_sims[input_id]\n",
    "\n",
    "    ## combine into final scores\n",
    "    scores = summary_scores * genre_scores\n",
    "    scores = list(enumerate(scores))\n",
    "\n",
    "    ## retrieve 10 highest scores\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    indices = [i[0] for i in scores[0:10]]\n",
    "    output = df[['title','year','genres','tmdbId','adj_rating','country']].iloc[indices]\n",
    "\n",
    "    ## reorder output using collaborative filtering\n",
    "    ## collect relevant user ratings\n",
    "    tmdb_id = df['tmdbId'].iloc[input_id]\n",
    "    similar_users = set(ratings[(ratings['tmdbId']==tmdb_id) & (ratings['rating']>=4.5)]['userId'])\n",
    "    mean_ratings = ratings[(ratings['userId'].isin(similar_users)) & (ratings['tmdbId'].isin(output['tmdbId']))]\n",
    "\n",
    "    if mean_ratings['title'].nunique() < 8:\n",
    "        output = output.sort_values('adj_rating',ascending=False)[0:5]\n",
    "        return output.reset_index()[['title','year','country']]\n",
    "    else:\n",
    "        mean_ratings = mean_ratings.groupby('tmdbId')[['title','rating','year','country']].agg(title=('title','first'), year=('year','first'), country=('country','first'), mean=('rating','mean'), count=('rating','count'))\n",
    "        mean_ratings['adj_rating'] = mean_ratings.apply(lambda x: adjust_rating(x['mean'],x['count']), axis=1)\n",
    "        mean_ratings = mean_ratings.sort_values(by='adj_rating', ascending=False).iloc[0:5]\n",
    "        return mean_ratings.reset_index()[['title','year','country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
